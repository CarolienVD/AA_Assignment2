{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "Recommended model for beginners: <b>EfficientNetB0</b> (computationally efficient while maintaining strong performance)\n",
    "\n",
    "Alternatives:\n",
    "- ResNet50: Great for deep learning with residual connections (preventing gradient issues), but can be heavy on computation for larger datasets\n",
    "- InceptionV3: Very powerful for complex image features, but slightly more computationally expensive than EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cl = pd.read_pickle(\"intermediate/train_df_clean.pkl\") # replace by cleaned df\n",
    "display(df_train_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths_of_square_images(path):\n",
    "    new_paths = []\n",
    "    views = ['front', 'right', 'back', 'left']\n",
    "    parts = path.replace(\".jpg\", \"\").split(\"/\")\n",
    "    for view in views:\n",
    "        path = 'train_images_square/' + f\"{parts[1]}/{parts[2]}_{view}.jpg\"\n",
    "        new_paths.append(path)\n",
    "    return new_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_paths_of_square_images(\"images/italy/1741683573_45.0502728_7.0621625.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "square_image_paths = df_train_cl['path'].apply(get_paths_of_square_images).sum()\n",
    "square_image_paths[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to 'path' column and create a new column 'new_paths'\n",
    "df_train_cl['square_image_paths'] = df_train_cl['path'].apply(get_paths_of_square_images)\n",
    "\n",
    "# Explode the new column into multiple rows\n",
    "df_train_cl = df_train_cl.explode('square_image_paths', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EfficientNetB0 without the top layers (classification layers)\n",
    "\n",
    "model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model\n",
    "\n",
    "model_finetune = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),   # Flip images horizontally\n",
    "    layers.RandomBrightness(0.2),       # Randomly adjust the brightness by up to 20%\n",
    "    layers.RandomContrast(0.1),\n",
    "    layers.RandomZoom(0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_finetune.add(data_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the base EfficientNetB0 model\n",
    "\n",
    "model_finetune.add(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a global average pooling layer to reduce the dimensions\n",
    "\n",
    "model_finetune.add(GlobalAveragePooling2D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a fully connected dense layer\n",
    "\n",
    "# model_finetune.add(Dense(1024, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a dropout layer to reduce overfitting\n",
    "\n",
    "# model_finetune.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_finetune.add(Dense(256, activation='relu'))\n",
    "# model_finetune.add(Dropout(0.5))\n",
    "model_finetune.add(Dense(512, activation='relu'))\n",
    "model_finetune.add(Dropout(0.4))\n",
    "model_finetune.add(Dense(128, activation='relu'))\n",
    "model_finetune.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer with the number of classes you have in your dataset (e.g., countries or regions)\n",
    "\n",
    "model_finetune.add(Dense(df_train_cl['region_cluster'].nunique(), activation='softmax'))  # Replace num_classes with the number of regions or countries you want to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train_cl['region_cluster'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the EfficientNetB0 base model layers\n",
    "\n",
    "model_finetune.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model_finetune.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy']) # set learning rate less small?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=df_train_cl,  # Assuming df has columns 'path' and 'majority_country'\n",
    "    x_col='square_image_paths',\n",
    "    y_col='region_cluster',\n",
    "    target_size=(224, 224),  # Resize images to fit the model\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Since it's a multi-class classification problem\n",
    "    subset='training'  # Set as 'training' or 'validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem: slices from same panoramic picture can be both in training and validation set -> is this data leakage? \n",
    "\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=df_train_cl,  \n",
    "    x_col='square_image_paths',\n",
    "    y_col='region_cluster',\n",
    "    target_size=(224, 224),  # Resize images to fit the model\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "history = model_finetune.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=3, restore_best_weights=True),  # Stops early if validation performance doesn't improve\n",
    "        ModelCheckpoint('best_model.keras', save_best_only=True)  # Save the best model during training\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model: Unfreeze some layers\n",
    "\n",
    "model.trainable = True\n",
    "for layer in model.layers[:150]:\n",
    "    layer.trainable = False  # Freeze the first 150 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-compile the model after unfreezing\n",
    "\n",
    "model_finetune.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "\n",
    "history_finetune = model_finetune.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=3, restore_best_weights=True),  # Stops early if validation performance doesn't improve\n",
    "        ModelCheckpoint('best_model_ft.keras', save_best_only=True)  # Save the best model during training\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
